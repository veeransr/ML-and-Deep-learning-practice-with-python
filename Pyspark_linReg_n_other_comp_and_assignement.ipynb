{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Pyspark-linReg n other comp and assignement.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veeransr/ML-and-Deep-learning-practice-with-python/blob/master/Pyspark_linReg_n_other_comp_and_assignement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpI-dTdQ6cyX",
        "colab_type": "text"
      },
      "source": [
        "Welcome to the final project of  “Apache Spark for Scalable Machine Learning on BigData”. In this assignment you’ll analyze a real-world dataset and apply machine learning on it using Apache Spark. \n",
        "\n",
        "In order to pass, you need to implement some code (as described in the instruction section on Coursera) and finally answer a quiz on the Coursera platform.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88YU9a4M6cyY",
        "colab_type": "text"
      },
      "source": [
        "This notebook is designed to run in a IBM Watson Studio default runtime (NOT the Watson Studio Apache Spark Runtime as the default runtime with 1 vCPU is free of charge). Therefore, we install Apache Spark in local mode for test purposes only. Please don't use it in production.\n",
        "\n",
        "In case you are facing issues, please read the following two documents first:\n",
        "\n",
        "https://github.com/IBM/skillsnetwork/wiki/Environment-Setup\n",
        "\n",
        "https://github.com/IBM/skillsnetwork/wiki/FAQ\n",
        "\n",
        "Then, please feel free to ask:\n",
        "\n",
        "https://coursera.org/learn/machine-learning-big-data-apache-spark/discussions/all\n",
        "\n",
        "Please make sure to follow the guidelines before asking a question:\n",
        "\n",
        "https://github.com/IBM/skillsnetwork/wiki/FAQ#im-feeling-lost-and-confused-please-help-me\n",
        "\n",
        "\n",
        "If running outside Watson Studio, this should work as well. In case you are running in an Apache Spark context outside Watson Studio, please remove the Apache Spark setup in the first notebook cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNrdPY-jr5jQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ipkfP2DsCFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iDRVkBQsErZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l49NSLSPsN4a",
        "colab_type": "code",
        "outputId": "156bf63e-244c-4608-f6f2-f7581836e7c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/5a/271c416c1c2185b6cb0151b29a91fff6fcaed80173c8584ff6d20e46b465/pyspark-2.4.5.tar.gz (217.8MB)\n",
            "\u001b[K     |████████████████████████████████| 217.8MB 61kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 48.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.5-py2.py3-none-any.whl size=218257927 sha256=18c5783029295b4c52693d22b39d082cda2f8b3e610495c39de4b69598907d27\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/db/04/61d66a5939364e756eb1c1be4ec5bdce6e04047fc7929a3c3c\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggASSG_msFKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import PCA\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.mllib.regression import LabeledPoint\n",
        "from pyspark.mllib.util import MLUtils\n",
        "import numpy as np\n",
        "from pyspark.ml.feature import StandardScaler\n",
        "import pyspark.sql.functions as f\n",
        "import pyspark.sql.types\n",
        "import pandas as pd\n",
        "from pyspark.sql import Row\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "sc = SparkContext.getOrCreate()\n",
        "from pyspark.ml.feature import VectorAssembler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2De_VYpb6cyn",
        "colab_type": "text"
      },
      "source": [
        "Let’s start by downloading the dataset and creating a dataframe. This dataset can be found on DAX, the IBM Data Asset Exchange and can be downloaded for free.\n",
        "\n",
        "https://developer.ibm.com/exchanges/data/all/jfk-weather-data/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeF0TKWn6cyo",
        "colab_type": "code",
        "outputId": "925a4a8d-181e-4e02-a3d0-a62deae0575f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# delete files from previous runs\n",
        "!rm -f jfk_weather*\n",
        "\n",
        "# download the file containing the data in CSV format\n",
        "!wget http://max-training-data.s3-api.us-geo.objectstorage.softlayer.net/noaa-weather/jfk_weather.tar.gz\n",
        "\n",
        "# extract the data\n",
        "!tar xvfz jfk_weather.tar.gz\n",
        "    \n",
        "# create a dataframe out of it by using the first row as field names and trying to infer a schema based on contents\n",
        "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\",\"true\").csv('jfk_weather.csv')\n",
        "\n",
        "# register a corresponding query table\n",
        "df.createOrReplaceTempView('df')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-27 20:58:03--  http://max-training-data.s3-api.us-geo.objectstorage.softlayer.net/noaa-weather/jfk_weather.tar.gz\n",
            "Resolving max-training-data.s3-api.us-geo.objectstorage.softlayer.net (max-training-data.s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
            "Connecting to max-training-data.s3-api.us-geo.objectstorage.softlayer.net (max-training-data.s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2575759 (2.5M) [application/x-tar]\n",
            "Saving to: ‘jfk_weather.tar.gz’\n",
            "\n",
            "jfk_weather.tar.gz  100%[===================>]   2.46M   489KB/s    in 5.1s    \n",
            "\n",
            "2020-05-27 20:58:08 (496 KB/s) - ‘jfk_weather.tar.gz’ saved [2575759/2575759]\n",
            "\n",
            "./._jfk_weather.csv\n",
            "jfk_weather.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-VAZTOl7dHU",
        "colab_type": "code",
        "outputId": "8923adbf-5edb-4b72-f748-62f0924e253c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "df.describe().show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+--------------------+------------------+------------------+------------------+----------------+----------+--------------------+------------------+-----------------------+------------------+------------------+------------------+------------------+-------------------+-------------------+----------------------+------------------+-------------------+-------------------+---------------------+----------------------+--------------------+----------------------+-------------------+----------------------+-----------------------+-----------------------+-----------------------+------------------------------+----------------------------+------------------------+-----------------------+----------------------+----------------------+-----------------+------------------+--------------------+-------------------+------------------+-----------------+---------------------------+----------------------------+---------------------+------------------+------------------+-----------------------+---------------------------+------------------+------------------+-----------------+----------------+-------------------+------------------+---------------------------+---------------------------+----------------------+-----------------------+-----------------------+--------------------+--------------------------------+--------------------------------+--------------------------------+---------------------------+------------------------+---------------------+-------------------------+-----------------------+---------------------------+------------------------+----------------------------+-----------------------+-----------------------+-----------------------+----------------------+--------------------------+--------------------------+----------------------+-------------------------------+------------------------------+------------------------------+-------------------------------+------------------------------+------------------------------+-----------------------------+-----------------------------+------------------------------+------------------------------+---------------------------------+---------------------------------+\n",
            "|summary|   STATION|        STATION_NAME|         ELEVATION|          LATITUDE|         LONGITUDE|            DATE|REPORTTPYE| HOURLYSKYCONDITIONS|  HOURLYVISIBILITY|HOURLYPRSENTWEATHERTYPE|HOURLYDRYBULBTEMPF|HOURLYDRYBULBTEMPC|HOURLYWETBULBTEMPF|HOURLYWETBULBTEMPC|HOURLYDewPointTempF|HOURLYDewPointTempC|HOURLYRelativeHumidity|   HOURLYWindSpeed|HOURLYWindDirection|HOURLYWindGustSpeed|HOURLYStationPressure|HOURLYPressureTendency|HOURLYPressureChange|HOURLYSeaLevelPressure|       HOURLYPrecip|HOURLYAltimeterSetting|DAILYMaximumDryBulbTemp|DAILYMinimumDryBulbTemp|DAILYAverageDryBulbTemp|DAILYDeptFromNormalAverageTemp|DAILYAverageRelativeHumidity|DAILYAverageDewPointTemp|DAILYAverageWetBulbTemp|DAILYHeatingDegreeDays|DAILYCoolingDegreeDays|     DAILYSunrise|       DAILYSunset|        DAILYWeather|        DAILYPrecip|     DAILYSnowfall|   DAILYSnowDepth|DAILYAverageStationPressure|DAILYAverageSeaLevelPressure|DAILYAverageWindSpeed|DAILYPeakWindSpeed| PeakWindDirection|DAILYSustainedWindSpeed|DAILYSustainedWindDirection|MonthlyMaximumTemp|MonthlyMinimumTemp|  MonthlyMeanTemp|MonthlyAverageRH|MonthlyDewpointTemp|MonthlyWetBulbTemp|MonthlyAvgHeatingDegreeDays|MonthlyAvgCoolingDegreeDays|MonthlyStationPressure|MonthlySeaLevelPressure|MonthlyAverageWindSpeed|MonthlyTotalSnowfall|MonthlyDeptFromNormalMaximumTemp|MonthlyDeptFromNormalMinimumTemp|MonthlyDeptFromNormalAverageTemp|MonthlyDeptFromNormalPrecip|MonthlyTotalLiquidPrecip|MonthlyGreatestPrecip|MonthlyGreatestPrecipDate|MonthlyGreatestSnowfall|MonthlyGreatestSnowfallDate|MonthlyGreatestSnowDepth|MonthlyGreatestSnowDepthDate|MonthlyDaysWithGT90Temp|MonthlyDaysWithLT32Temp|MonthlyDaysWithGT32Temp|MonthlyDaysWithLT0Temp|MonthlyDaysWithGT001Precip|MonthlyDaysWithGT010Precip|MonthlyDaysWithGT1Snow|MonthlyMaxSeaLevelPressureValue|MonthlyMaxSeaLevelPressureDate|MonthlyMaxSeaLevelPressureTime|MonthlyMinSeaLevelPressureValue|MonthlyMinSeaLevelPressureDate|MonthlyMinSeaLevelPressureTime|MonthlyTotalHeatingDegreeDays|MonthlyTotalCoolingDegreeDays|MonthlyDeptFromNormalHeatingDD|MonthlyDeptFromNormalCoolingDD|MonthlyTotalSeasonToDateHeatingDD|MonthlyTotalSeasonToDateCoolingDD|\n",
            "+-------+----------+--------------------+------------------+------------------+------------------+----------------+----------+--------------------+------------------+-----------------------+------------------+------------------+------------------+------------------+-------------------+-------------------+----------------------+------------------+-------------------+-------------------+---------------------+----------------------+--------------------+----------------------+-------------------+----------------------+-----------------------+-----------------------+-----------------------+------------------------------+----------------------------+------------------------+-----------------------+----------------------+----------------------+-----------------+------------------+--------------------+-------------------+------------------+-----------------+---------------------------+----------------------------+---------------------+------------------+------------------+-----------------------+---------------------------+------------------+------------------+-----------------+----------------+-------------------+------------------+---------------------------+---------------------------+----------------------+-----------------------+-----------------------+--------------------+--------------------------------+--------------------------------+--------------------------------+---------------------------+------------------------+---------------------+-------------------------+-----------------------+---------------------------+------------------------+----------------------------+-----------------------+-----------------------+-----------------------+----------------------+--------------------------+--------------------------+----------------------+-------------------------------+------------------------------+------------------------------+-------------------------------+------------------------------+------------------------------+-----------------------------+-----------------------------+------------------------------+------------------------------+---------------------------------+---------------------------------+\n",
            "|  count|    114545|              114545|            114545|            114545|            114545|          114545|    114545|               93335|             96464|                  19974|            111405|            111405|            111247|            111247|             111397|             111397|                111397|            111358|             111237|              15476|               111256|                 48038|               29170|                 99522|              79763|                 86878|                  10872|                  10934|                   9693|                          9687|                        2532|                    2640|                   2640|                  9693|                  9693|           114545|            114545|                1479|               5134|              3130|             4793|                       3127|                        2637|                 3112|              3057|              3057|                   3111|                       3111|               100|                99|               99|               0|                  0|                 0|                          1|                          1|                    90|                     90|                      1|                 290|                             100|                              99|                              99|                         93|                      93|                    0|                        0|                     89|                         38|                      89|                          29|                     97|                     97|                     97|                    97|                         0|                         0|                     1|                              0|                        114545|                        114545|                              0|                        114545|                        114545|                          101|                          101|                           101|                           101|                                1|                                1|\n",
            "|   mean|      null|                null|3.3999999999964845|40.638599999988074|-73.76220000008068|            null|      null|  36.320351137487634| 8.769363625982491|                   null| 55.31025753808314| 12.95015484600692| 49.70309676839408| 9.836674007820323|  43.31362126245847|   6.28538924306369|     67.13214237622874|11.267868207656456|  192.5115895838615|  28.42536831222538|    29.99106341454733|     4.388962904367376|5.829903978052094E-4|    30.026475247524782|0.00752132144584965|     30.01000115175567|     61.560706401766005|     48.563471739528076|     54.927060765500876|             0.483173325074839|           64.10110584518168|      42.294318181818184|      49.28409090909091|    12.999277829361395|    2.9263385948622718|561.1988912654415|1785.0249596228557|                null|0.23063395570994222|0.1588903743315508|1.602332222751071|         29.998768787975695|          30.024137277208958|   11.294955012853473|27.950278050376184|215.66895649329408|      21.98296367727419|         217.02667952426873|62.501000000000005|  47.8949494949495|55.22222222222222|            null|               null|              null|                        4.0|                      218.0|    30.003111111111107|     30.028888888888883|                    9.4|   3.127631578947368|              1.3890000000000002|              1.0808080808080807|              1.2565656565656567|       -0.14945652173913046|      3.4154347826086964|                 null|                     null|     1.6590909090909094|                       null|      3.1839080459770117|          13.310344827586206|      1.092783505154639|      1.288659793814433|      6.268041237113402|                   0.0|                      null|                      null|                   0.0|                           null|                       -9999.0|                       -9999.0|                           null|                       -9999.0|                       -9999.0|            351.1807228915663|             70.6067415730337|            -6.421686746987952|              9.44943820224719|                           4898.0|                            274.0|\n",
            "| stddev|      null|                null|               0.0|               0.0|               0.0|            null|      null|   21.77074864355607|2.7300334108150888|                   null| 17.16969104448122| 9.538667964316257| 16.06211329291024| 8.924103079636549|  19.35399553012375|  10.75174309476341|    20.278571214732896| 6.174750499148175| 107.60651557298513|  6.510897043931792|   0.2377972209133701|    2.7417948914310277| 0.04740405670588989|   0.23321448782009285|0.04412303029623243|   0.23910262552781503|     17.441266232757727|     16.852759388426175|      16.83352807199125|             6.788689696089988|           15.94704438992545|      18.779592686410915|     15.651918199337429|    13.492110299610491|    5.0241616560716285|103.0674100713479| 105.5816817020771|                null|0.46512262375068164|1.3346604289967479|3.370570687776626|        0.22051745101919398|         0.22056896552547803|     4.33437482700981| 8.641803804301185| 98.95107103061476|      6.707343412342313|          97.00034273417002| 16.34782594510087|15.816378579655149|16.10689138578201|            null|               null|              null|                        NaN|                        NaN|   0.08245726771335203|     0.0832681392924284|                    NaN|   5.092901141348855|              3.3050587182852187|              3.2245447952014192|               3.204498165562622|         1.7702618941594612|      1.7446933122877817|                 null|                     null|      3.985941858254793|                       null|      11.935416064914072|            7.99152876611881|     2.5086619700001607|     2.9789496292268507|      8.970455516023055|                   0.0|                      null|                      null|                   NaN|                           null|                           0.0|                           0.0|                           null|                           0.0|                           0.0|           373.10647615753146|           118.52661937087919|             61.12165407709602|            21.613869303567693|                              NaN|                              NaN|\n",
            "|    min|WBAN:94789|JFK INTERNATIONAL...|               3.4|           40.6386|          -73.7622|2010-01-01 00:51|     FM-12|                   1|              0.00|   +RA:02 BR:1 |RA:63 ||                 *|                 *|                 *|                 *|                  *|                  *|                     *|                 0|                000|                 16|                28.49|                     0|               +0.00|                 28.54|               0.00|                 28.51|                     11|                      1|                      9|                         -26.0|                          20|                     -14|                      7|                     0|                     0|              423|              1628|               BR:13|               0.00|               0.0|                0|                      29.07|                       29.02|                  1.9|                 8|                10|                      7|                         10|              32.6|              16.5|             24.5|            null|               null|              null|                          4|                        218|                 29.75|                  29.77|                    9.4|                 0.1|                            -9.2|                           -11.6|                           -10.4|                      -0.05|                    0.33|                 null|                     null|                    0.0|                      02-02|                       0|                           1|                      0|                      0|                      0|                     0|                      null|                      null|                     0|                           null|                         -9999|                         -9999|                           null|                         -9999|                         -9999|                            0|                            0|                            -1|                           -12|                             4898|                              274|\n",
            "|    max|WBAN:94789|JFK INTERNATIONAL...|               3.4|           40.6386|          -73.7622|2018-07-27 23:59|     SY-MT|X:10 0 SCT:04 8 O...|             99.42|                ||TS:95|                99|               9.9|                 9|               9.9|                  9|                9.4|                    97|                 9|                VRB|                 79|                30.83|                     8|                0.14|                 30.85|                  T|                 30.85|                    103|                     88|                     90|                          27.6|                         100|                      76|                     79|                    56|                    25|              719|              1930|TS:03 RA:16 SN:18...|                  T|                 T|                T|                      30.76|                       30.76|                 36.2|                85|               360|                     56|                        360|              89.0|              72.5|             80.8|            null|               null|              null|                          4|                        218|                 30.21|                  30.23|                    9.4|                   T|                            12.4|                            12.7|                            12.6|                       4.84|                    8.62|                 null|                     null|                      T|                      29-29|                       T|                          28|                     13|                     14|                     28|                     0|                      null|                      null|                     0|                           null|                         -9999|                         -9999|                           null|                         -9999|                         -9999|                          986|                           71|                             9|                           91s|                             4898|                              274|\n",
            "+-------+----------+--------------------+------------------+------------------+------------------+----------------+----------+--------------------+------------------+-----------------------+------------------+------------------+------------------+------------------+-------------------+-------------------+----------------------+------------------+-------------------+-------------------+---------------------+----------------------+--------------------+----------------------+-------------------+----------------------+-----------------------+-----------------------+-----------------------+------------------------------+----------------------------+------------------------+-----------------------+----------------------+----------------------+-----------------+------------------+--------------------+-------------------+------------------+-----------------+---------------------------+----------------------------+---------------------+------------------+------------------+-----------------------+---------------------------+------------------+------------------+-----------------+----------------+-------------------+------------------+---------------------------+---------------------------+----------------------+-----------------------+-----------------------+--------------------+--------------------------------+--------------------------------+--------------------------------+---------------------------+------------------------+---------------------+-------------------------+-----------------------+---------------------------+------------------------+----------------------------+-----------------------+-----------------------+-----------------------+----------------------+--------------------------+--------------------------+----------------------+-------------------------------+------------------------------+------------------------------+-------------------------------+------------------------------+------------------------------+-----------------------------+-----------------------------+------------------------------+------------------------------+---------------------------------+---------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vv-48i9o6cyr",
        "colab_type": "text"
      },
      "source": [
        "The dataset contains some null values, therefore schema inference didn’t work properly for all columns, in addition, a column contained trailing characters, so we need to clean up the data set first. This is a normal task in any data science project since your data is never clean, don’t worry if you don’t understand all code, you won’t be asked about it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUjvyr8r6cys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "from pyspark.sql.functions import translate, col\n",
        "\n",
        "df_cleaned = df \\\n",
        "    .withColumn(\"HOURLYWindSpeed\", df.HOURLYWindSpeed.cast('double')) \\\n",
        "    .withColumn(\"HOURLYWindDirection\", df.HOURLYWindDirection.cast('double')) \\\n",
        "    .withColumn(\"HOURLYStationPressure\", translate(col(\"HOURLYStationPressure\"), \"s,\", \"\")) \\\n",
        "    .withColumn(\"HOURLYPrecip\", translate(col(\"HOURLYPrecip\"), \"s,\", \"\")) \\\n",
        "    .withColumn(\"HOURLYRelativeHumidity\", translate(col(\"HOURLYRelativeHumidity\"), \"*\", \"\")) \\\n",
        "    .withColumn(\"HOURLYDRYBULBTEMPC\", translate(col(\"HOURLYDRYBULBTEMPC\"), \"*\", \"\")) \\\n",
        "\n",
        "df_cleaned =   df_cleaned \\\n",
        "                    .withColumn(\"HOURLYStationPressure\", df_cleaned.HOURLYStationPressure.cast('double')) \\\n",
        "                    .withColumn(\"HOURLYPrecip\", df_cleaned.HOURLYPrecip.cast('double')) \\\n",
        "                    .withColumn(\"HOURLYRelativeHumidity\", df_cleaned.HOURLYRelativeHumidity.cast('double')) \\\n",
        "                    .withColumn(\"HOURLYDRYBULBTEMPC\", df_cleaned.HOURLYDRYBULBTEMPC.cast('double')) \\\n",
        "\n",
        "df_filtered = df_cleaned.filter(\"\"\"\n",
        "    HOURLYWindSpeed <> 0\n",
        "    and HOURLYWindSpeed IS NOT NULL\n",
        "    and HOURLYWindDirection IS NOT NULL\n",
        "    and HOURLYStationPressure IS NOT NULL\n",
        "    and HOURLYPressureTendency IS NOT NULL\n",
        "    and HOURLYPrecip IS NOT NULL\n",
        "    and HOURLYRelativeHumidity IS NOT NULL\n",
        "    and HOURLYDRYBULBTEMPC IS NOT NULL\n",
        "\"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM-8Kncz6cyw",
        "colab_type": "text"
      },
      "source": [
        "We want to predict the value of one column based of some others. It is sometimes helpful to print a correlation matrix. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOoj3u8y6cyx",
        "colab_type": "code",
        "outputId": "62012e65-6b1c-4f47-ac34-f94f3f3185be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "vectorAssembler = VectorAssembler(inputCols=[\"HOURLYWindSpeed\",\"HOURLYWindDirection\",\"HOURLYStationPressure\"],\n",
        "                                  outputCol=\"features\")\n",
        "df_pipeline = vectorAssembler.transform(df_filtered)\n",
        "from pyspark.ml.stat import Correlation\n",
        "Correlation.corr(df_pipeline,\"features\").head()[0].toArray()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.        ,  0.25478863, -0.26171147],\n",
              "       [ 0.25478863,  1.        , -0.13377466],\n",
              "       [-0.26171147, -0.13377466,  1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDP3KWSBAKGN",
        "colab_type": "code",
        "outputId": "f3617942-f325-4a8d-de8e-d24919d7edad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "vectorAssembler = VectorAssembler(inputCols=[\"HOURLYWindSpeed\",\"HOURLYPressureTendency\",\"HOURLYStationPressure\"],\n",
        "                                  outputCol=\"features\")\n",
        "df_pipeline = vectorAssembler.transform(df_filtered)\n",
        "from pyspark.ml.stat import Correlation\n",
        "Correlation.corr(df_pipeline,\"features\").head()[0].toArray()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.        , -0.01324305, -0.26171147],\n",
              "       [-0.01324305,  1.        , -0.05821663],\n",
              "       [-0.26171147, -0.05821663,  1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GSVlw5w6cy0",
        "colab_type": "text"
      },
      "source": [
        "As we can see, HOURLYWindSpeed and HOURLYWindDirection correlate with 0.25478863 whereas HOURLYWindSpeed  and HOURLYStationPressure correlate with -0.26171147, this is a good sign if we want to predict HOURLYWindSpeed from HOURLYWindDirection and HOURLYStationPressure. Note that the numbers can change over time as we are always working with the latest data.\n",
        "Since this is supervised learning, let’s split our data into train (80%) and test (20%) set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIcHYRa06cy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "splits = df_filtered.randomSplit([0.8, 0.2])\n",
        "df_train = splits[0]\n",
        "df_test = splits[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-gv2nBr6cy4",
        "colab_type": "text"
      },
      "source": [
        "Again, we can re-use our feature engineering pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Y9ZPLg6cy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.feature import Normalizer\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "vectorAssembler = VectorAssembler(inputCols=[\n",
        "                                    \"HOURLYWindDirection\",\n",
        "                                    \"ELEVATION\",\n",
        "                                    \"HOURLYStationPressure\"],\n",
        "                                  outputCol=\"features\")\n",
        "\n",
        "normalizer = Normalizer(inputCol=\"features\", outputCol=\"features_norm\", p=1.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8YwIity6cy7",
        "colab_type": "text"
      },
      "source": [
        "Now we define a function for evaluating our regression prediction performance. We’re using RMSE (Root Mean Squared Error) here , the smaller the better…\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvWM7pww6cy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def regression_metrics(prediction):\n",
        "    from pyspark.ml.evaluation import RegressionEvaluator\n",
        "    evaluator = RegressionEvaluator(\n",
        "    labelCol=\"HOURLYWindSpeed\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "    rmse = evaluator.evaluate(prediction)\n",
        "    print(\"RMSE on test data = %g\" % rmse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYbyCOn46cy_",
        "colab_type": "text"
      },
      "source": [
        "Let’s run a linear regression model first for building a baseline.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PybBW7Sw6czA",
        "colab_type": "code",
        "outputId": "d4f4777c-86eb-4dd0-db64-505cb3fc7fa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#LR1\n",
        "\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "\n",
        "lr = LinearRegression(labelCol=\"HOURLYWindSpeed\", featuresCol='features', maxIter=100, regParam=0.0, elasticNetParam=0.0)\n",
        "pipeline = Pipeline(stages=[vectorAssembler, normalizer,lr])\n",
        "model = pipeline.fit(df_train)\n",
        "prediction = model.transform(df_test)\n",
        "regression_metrics(prediction)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE on test data = 5.30775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtsFgVblBKEu",
        "colab_type": "code",
        "outputId": "8aa873b6-bc26-4fb6-c2f2-01ea5b6ad789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#LR1_with_features_norm\n",
        "\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "\n",
        "lr = LinearRegression(labelCol=\"HOURLYWindSpeed\", featuresCol='features_norm', maxIter=100, regParam=0.0, elasticNetParam=0.0)\n",
        "pipeline = Pipeline(stages=[vectorAssembler, normalizer,lr])\n",
        "model = pipeline.fit(df_train)\n",
        "prediction = model.transform(df_test)\n",
        "regression_metrics(prediction)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE on test data = 0.914067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRWeydPW6czD",
        "colab_type": "text"
      },
      "source": [
        "Now we’ll try a Gradient Boosted Tree Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFVqsT_F6czE",
        "colab_type": "code",
        "outputId": "dfdc867f-85de-4034-b229-26de5d88ba6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#GBT1\n",
        "\n",
        "from pyspark.ml.regression import GBTRegressor\n",
        "gbt = GBTRegressor(labelCol=\"HOURLYWindSpeed\", maxIter=100)\n",
        "pipeline = Pipeline(stages=[vectorAssembler, normalizer,gbt])\n",
        "model = pipeline.fit(df_train)\n",
        "prediction = model.transform(df_test)\n",
        "regression_metrics(prediction)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE on test data = 5.13095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLDndYMv6czG",
        "colab_type": "text"
      },
      "source": [
        "Now let’s switch gears. Previously, we tried to predict HOURLYWindSpeed, but now we predict HOURLYWindDirection. In order to turn this into a classification problem we discretize the value using the Bucketizer. The new feature is called HOURLYWindDirectionBucketized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1HBjsR06czH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import Bucketizer, OneHotEncoder\n",
        "bucketizer = Bucketizer(splits=[ 0, 180, float('Inf') ],inputCol=\"HOURLYWindDirection\", outputCol=\"HOURLYWindDirectionBucketized\")\n",
        "encoder = OneHotEncoder(inputCol=\"HOURLYWindDirectionBucketized\", outputCol=\"HOURLYWindDirectionOHE\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcxsHDcW6czK",
        "colab_type": "text"
      },
      "source": [
        "Again, we define a function in order to assess how we perform. Here we just use the accuracy measure which gives us the fraction of correctly classified examples. Again, 0 is bad, 1 is good."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR1TKRan6czL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classification_metrics(prediction):\n",
        "    from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "    mcEval = MulticlassClassificationEvaluator().setMetricName(\"accuracy\") .setPredictionCol(\"prediction\").setLabelCol(\"HOURLYWindDirectionBucketized\")\n",
        "    accuracy = mcEval.evaluate(prediction)\n",
        "    print(\"Accuracy on test data = %g\" % accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZMhyMSg6czS",
        "colab_type": "text"
      },
      "source": [
        "Again, for baselining we use LogisticRegression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVgL7Je86czS",
        "colab_type": "code",
        "outputId": "cab8d75f-9754-4501-c5da-a5b75c2276e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#LGReg1\n",
        "\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "lr = LogisticRegression(labelCol=\"HOURLYWindDirectionBucketized\", maxIter=10)\n",
        "#,\"ELEVATION\",\"HOURLYStationPressure\",\"HOURLYPressureTendency\",\"HOURLYPrecip\"\n",
        "\n",
        "vectorAssembler = VectorAssembler(inputCols=[\"HOURLYWindSpeed\",\"HOURLYDRYBULBTEMPC\"],\n",
        "                                  outputCol=\"features\")\n",
        "\n",
        "pipeline = Pipeline(stages=[bucketizer,vectorAssembler,normalizer,lr])\n",
        "model = pipeline.fit(df_train)\n",
        "prediction = model.transform(df_test)\n",
        "classification_metrics(prediction)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test data = 0.692922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H47db5BH6czW",
        "colab_type": "text"
      },
      "source": [
        "Let’s try some other Algorithms and see if model performance increases. It’s also important to tweak other parameters like parameters of individual algorithms (e.g. number of trees for RandomForest) or parameters in the feature engineering pipeline, e.g. train/test split ratio, normalization, bucketing, …"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dR4_NCGCM3F",
        "colab_type": "code",
        "outputId": "a9784656-6bfc-4751-b776-22702615c5ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#RF1\n",
        "\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "rf = RandomForestClassifier(labelCol=\"HOURLYWindDirectionBucketized\", numTrees=30)\n",
        "\n",
        "vectorAssembler = VectorAssembler(inputCols=[\"HOURLYWindSpeed\",\"HOURLYDRYBULBTEMPC\",\"ELEVATION\",\"HOURLYStationPressure\",\"HOURLYPressureTendency\",\"HOURLYPrecip\"],\n",
        "                                  outputCol=\"features\")\n",
        "\n",
        "pipeline = Pipeline(stages=[bucketizer,vectorAssembler,normalizer,rf])\n",
        "model = pipeline.fit(df_train)\n",
        "prediction = model.transform(df_test)\n",
        "classification_metrics(prediction)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test data = 0.717123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfiDxk7Z6czW",
        "colab_type": "code",
        "outputId": "0121de1c-84bc-4545-994f-0bc1d04781b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#RF1 from 30 to 10\n",
        "\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "rf = RandomForestClassifier(labelCol=\"HOURLYWindDirectionBucketized\", numTrees=10)\n",
        "\n",
        "vectorAssembler = VectorAssembler(inputCols=[\"HOURLYWindSpeed\",\"HOURLYDRYBULBTEMPC\",\"ELEVATION\",\"HOURLYStationPressure\",\"HOURLYPressureTendency\",\"HOURLYPrecip\"],\n",
        "                                  outputCol=\"features\")\n",
        "\n",
        "pipeline = Pipeline(stages=[bucketizer,vectorAssembler,normalizer,rf])\n",
        "model = pipeline.fit(df_train)\n",
        "prediction = model.transform(df_test)\n",
        "classification_metrics(prediction)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test data = 0.717808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZO0sm786czZ",
        "colab_type": "code",
        "outputId": "9969e706-6f40-43e3-b72a-2f4d586dd627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#GBT2\n",
        "\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "gbt = GBTClassifier(labelCol=\"HOURLYWindDirectionBucketized\", maxIter=100)\n",
        "\n",
        "vectorAssembler = VectorAssembler(inputCols=[\"HOURLYWindSpeed\",\"HOURLYDRYBULBTEMPC\",\"ELEVATION\",\"HOURLYStationPressure\",\"HOURLYPressureTendency\",\"HOURLYPrecip\"],\n",
        "                                  outputCol=\"features\")\n",
        "\n",
        "pipeline = Pipeline(stages=[bucketizer,vectorAssembler,normalizer,gbt])\n",
        "model = pipeline.fit(df_train)\n",
        "prediction = model.transform(df_test)\n",
        "classification_metrics(prediction)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test data = 0.734018\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}